{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvitOBEG/z55rTLO2yx28D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnPaiva93/metabook-es/blob/colab/metabook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hackathon Latin America 2024"
      ],
      "metadata": {
        "id": "dpVMA5R7jA3X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEZGQlMGR_5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tx-xIpTHSAP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "7_4n36vrSAkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_prompt = \"\"\"Usted es un escritor de podcast educativo de clase mundial, especializado en crear conversaciones atractivas y educativas sobre diversos temas. Su tarea es generar un diálogo de podcast entre dos oradores sobre el siguiente tema:\n",
        "\n",
        "\n",
        "<tema>\n",
        "\n",
        "{topic}\n",
        "\n",
        "</tema>\n",
        "\n",
        "\n",
        "Antes de comenzar el diálogo, planifique la estructura de la conversación dentro de las etiquetas <planificacion_podcast>. En esta sección:\n",
        "\n",
        "\n",
        "1. Divida el tema en 3-5 subtemas principales para cubrir durante la conversación.\n",
        "\n",
        "2. Para cada subtema, anote:\n",
        "\n",
        "   - Una pregunta clave que el Orador 2 podría hacer.\n",
        "\n",
        "   - Un punto principal que el Orador 1 debería explicar.\n",
        "\n",
        "   - Una posible anécdota o analogía que el Orador 1 podría usar para ilustrar el punto.\n",
        "\n",
        "   - 1-2 potenciales tangentes interesantes o preguntas inusuales que el Orador 2 podría plantear.\n",
        "\n",
        "3. Planifique una introducción atractiva y una conclusión que resuma los puntos clave.\n",
        "\n",
        "4. Sugiera 2-3 lugares donde el Orador 2 podría expresar confusión o pedir aclaraciones.\n",
        "\n",
        "5. Planifique transiciones específicas entre cada subtema para mantener un flujo natural de la conversación.\n",
        "\n",
        "\n",
        "Es aceptable que esta sección sea bastante larga para asegurar una planificación detallada.\n",
        "\n",
        "\n",
        "Después de planificar la estructura, genere el diálogo siguiendo estas instrucciones:\n",
        "\n",
        "\n",
        "1. Formato del diálogo:\n",
        "\n",
        "   - Use \"Orador 1:\" y \"Orador 2:\" para indicar quién está hablando.\n",
        "\n",
        "   - Incluya interrupciones naturales, como \"ahh\", \"esss\", \"correcto\", etc.\n",
        "\n",
        "   - No incluya títulos de episodios o capítulos separados.\n",
        "\n",
        "\n",
        "2. Roles de los oradores:\n",
        "\n",
        "   - Orador 1: Experto que dirige la conversación. Debe ser un profesor cautivador que ofrece explicaciones claras, anécdotas interesantes y analogías efectivas.\n",
        "\n",
        "   - Orador 2: Aprendiz curioso que mantiene el hilo de la conversación haciendo preguntas de seguimiento. Debe mostrar entusiasmo y ocasionalmente confusión, haciendo preguntas de confirmación interesantes.\n",
        "\n",
        "\n",
        "3. Estructura de la conversación:\n",
        "\n",
        "   - Comience con una bienvenida atractiva y un resumen del tema por parte del Orador 1.\n",
        "\n",
        "   - El Orador 2 debe hacer preguntas relevantes y ocasionalmente ir por tangentes interesantes o inusuales.\n",
        "\n",
        "   - El Orador 1 debe responder con explicaciones claras, utilizando anécdotas y analogías para ilustrar los puntos.\n",
        "\n",
        "   - Mantenga un equilibrio entre la información educativa y el entretenimiento.\n",
        "\n",
        "\n",
        "4. Contenido:\n",
        "\n",
        "   - Asegúrese de que la conversación se mantenga centrada en el tema principal, aunque se permiten breves desvíos.\n",
        "\n",
        "   - Incluya datos precisos y actualizados sobre el tema.\n",
        "\n",
        "   - Use ejemplos del mundo real para hacer el contenido más relatable y comprensible.\n",
        "\n",
        "\n",
        "5. Tono:\n",
        "\n",
        "   - Mantenga un tono educativo pero accesible y amigable.\n",
        "\n",
        "   - La conversación debe ser informativa pero también entretenida y atractiva para el oyente.\n",
        "\n",
        "   - Los oradores son mujeres.\n",
        "\n",
        "\n",
        "Presente su respuesta en el siguiente formato:\n",
        "\n",
        "\n",
        "<resultado>\n",
        "\n",
        "[Escriba aquí el resultado del tema de forma estructurada como wikipedia]\n",
        "\n",
        "</resultado>\n",
        "\n",
        "\n",
        "<dialogo>\n",
        "\n",
        "[Inserte aquí el diálogo completo del podcast, comenzando directamente con el Orador 1 dando la bienvenida a los oyentes]\n",
        "\n",
        "</dialogo>\n",
        "\n",
        "\n",
        "Asegúrese de que el diálogo refleje la estructura planificada y cumpla con todas las instrucciones proporcionadas.\"\"\""
      ],
      "metadata": {
        "id": "ECyolidmSDRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General"
      ],
      "metadata": {
        "id": "rFH0qf2-1l8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "9sK102g7SbmO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install groq streamlit ffmpeg-python gTTS pymupdf4llm pydub"
      ],
      "metadata": {
        "id": "HiwlRNi11lwk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install crewai #crewai-tools"
      ],
      "metadata": {
        "id": "tx7o6Dbe0NOn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install TTS"
      ],
      "metadata": {
        "id": "75ndhVYPbJvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install llama_index llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "id": "m5QRpXh5Mi0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install llama-index-vector-stores-chroma llama-index-llms-groq"
      ],
      "metadata": {
        "id": "yYLNTpGnlovH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install llama-index-llms-sambanovacloud\n",
        "# !pip install sseclient-py"
      ],
      "metadata": {
        "id": "gyjX1fe7QOXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "NPKNLd1k4WDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# %pip install llama-index-embeddings-openvino"
      ],
      "metadata": {
        "id": "3L25x5xyC495"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# %pip install llama-index-retrievers-bm25"
      ],
      "metadata": {
        "id": "e3BF35RbIW4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "5icSSYfRMOiB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "SAMBANOVA_API_KEY = userdata.get('SAMBANOVA_API_KEY')"
      ],
      "metadata": {
        "id": "UXW3YyfJKMru"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.embeddings.huggingface_openvino import OpenVINOEmbedding\n",
        "\n",
        "# OpenVINOEmbedding.create_and_save_openvino_model(\n",
        "#     \"sentence-transformers/all-MiniLM-L6-v2\", \"./models\"\n",
        "# )"
      ],
      "metadata": {
        "id": "95TInRCEDDL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "# from llama_index.llms.groq import Groq\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from llama_index.core import Settings\n",
        "\n",
        "# # model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device = \"cpu\", backend=\"openvino\")\n",
        "# # model.save_pretrained(\"path/to/my/model\")\n",
        "\n",
        "# Settings.embed_model = OpenVINOEmbedding(model_id_or_path=\"./models\", device=\"cpu\")\n",
        "\n",
        "# if not os.getenv(\"SAMBANOVA_API_KEY\"):\n",
        "#     os.environ[\"SAMBANOVA_API_KEY\"] = SAMBANOVA_API_KEY\n",
        "\n",
        "# # Settings.llm = SambaNovaCloud(\n",
        "# #     model=\"Meta-Llama-3.1-70B-Instruct\",\n",
        "# #     max_tokens=1024,\n",
        "# #     temperature=0.7,\n",
        "# #     top_k=1,\n",
        "# #     top_p=0.01,\n",
        "# # )\n",
        "\n",
        "# Settings.llm = Groq(model=\"llama3-70b-8192\", api_key=GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "Z_FKAtj8v-Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "FBQ4bzmq1Ufq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "def bytesio_to_ogg(input_bytesio: io.BytesIO, input_format: str = \"wav\", output_file: str = \"temp.ogg\"):\n",
        "    \"\"\"\n",
        "    Convert audio data from a BytesIO object to an OGG file using ffmpeg-python.\n",
        "\n",
        "    Args:\n",
        "        input_bytesio (BytesIO): The input audio data as a BytesIO object.\n",
        "        output_file (str): The path to save the converted OGG file.\n",
        "    \"\"\"\n",
        "    # Reset the BytesIO pointer to the start\n",
        "    input_bytesio.seek(0)\n",
        "\n",
        "    # Use ffmpeg to read from BytesIO and write to an OGG file\n",
        "    process = (\n",
        "        ffmpeg\n",
        "        .input('pipe:0', format=input_format)  # Adjust format if input is not WAV\n",
        "        .output(\n",
        "            output_file,\n",
        "            format='ogg',\n",
        "            acodec='libopus',  # Correct codec for OGG\n",
        "            ac=1,              # Mono audio\n",
        "            b='12k',           # Correct option for bitrate\n",
        "            application='voip' # Libopus-specific option\n",
        "        )\n",
        "        .overwrite_output()\n",
        "        .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True)\n",
        "    )\n",
        "\n",
        "    # Send BytesIO content to FFmpeg and capture any errors\n",
        "    stdout, stderr = process.communicate(input=input_bytesio.read())\n",
        "\n",
        "    if process.returncode != 0:\n",
        "        raise RuntimeError(f\"ffmpeg failed: {stderr.decode('utf-8')}\")\n",
        "\n",
        "    print(f\"Converted to OGG: {output_file}\")\n",
        "\n",
        "# Función para extraer contenido entre etiquetas específicas\n",
        "def extraer_contenido(texto, etiqueta):\n",
        "    \"\"\"\n",
        "    Extrae contenido encerrado dentro de etiquetas HTML/XML específicas en un texto.\n",
        "\n",
        "    Args:\n",
        "        texto (str): El texto fuente que contiene las etiquetas.\n",
        "        etiqueta (str): La etiqueta de la que se quiere extraer el contenido.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista con el contenido encontrado entre las etiquetas.\n",
        "    \"\"\"\n",
        "    patron = fr\"<{etiqueta}>(.*?)</{etiqueta}>\"\n",
        "    return re.findall(patron, texto, re.DOTALL)\n",
        "\n",
        "# Función para procesar los diálogos de dos oradores\n",
        "def procesar_dialogos(dialogo):\n",
        "    \"\"\"\n",
        "    Procesa un bloque de texto para separar los diálogos de Orador 1 y Orador 2.\n",
        "\n",
        "    Args:\n",
        "        dialogo (str): Texto fuente que contiene los diálogos.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Dos listas con los diálogos de Orador 1 y Orador 2, respectivamente.\n",
        "    \"\"\"\n",
        "    # Patrones para extraer diálogos de Orador 1 y Orador 2\n",
        "    orador1_patron = r\"Orador 1: (.*?)(?=(Orador 2:|$))\"\n",
        "    orador2_patron = r\"Orador 2: (.*?)(?=(Orador 1:|$))\"\n",
        "\n",
        "    # Encontrar diálogos y limpiar espacios\n",
        "    orador1_dialogos = [d[0].strip() for d in re.findall(orador1_patron, dialogo, re.DOTALL)]\n",
        "    orador2_dialogos = [d[0].strip() for d in re.findall(orador2_patron, dialogo, re.DOTALL)]\n",
        "\n",
        "    return orador1_dialogos, orador2_dialogos"
      ],
      "metadata": {
        "id": "HzQewFbMkFrH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input"
      ],
      "metadata": {
        "id": "LKHBFDM2z8vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librería\n",
        "import uuid\n",
        "import os, io, subprocess, ffmpeg\n",
        "from groq import Groq\n",
        "\n",
        "from pydantic import BaseModel, ConfigDict, Field"
      ],
      "metadata": {
        "id": "cAoDWJxt-1r5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Audio(BaseModel):\n",
        "    audio_bytes: io.BytesIO\n",
        "    id: str = Field(default=str(uuid.uuid4()))\n",
        "    audio_path: str = Field(default=None)\n",
        "    input_format: str = Field(default=\"wav\")\n",
        "    output_format: str = Field(default=\"ogg\")\n",
        "\n",
        "    def __init__(self, **data):\n",
        "        super().__init__(**data)\n",
        "        self.convert_to_ogg()\n",
        "        self.audio_path=self.id+\".\"+self.output_format\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def convert_to_ogg(self):\n",
        "        \"\"\"\n",
        "        Generar el audio temporal en formato ogg\n",
        "        \"\"\"\n",
        "        output_file=self.id+\".\"+self.output_format\n",
        "        self.audio_bytes.seek(0)\n",
        "        bytesio_to_ogg(self.audio_bytes, self.input_format, output_file)\n",
        "\n",
        "class STT(BaseModel):\n",
        "  client: Groq = None\n",
        "\n",
        "  class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "  def __init__(self, **data):\n",
        "        super().__init__(**data)\n",
        "        self.client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "  def obtener_texto(self, audio: Audio):\n",
        "        \"\"\"\n",
        "        Transcribes audio and returns the text.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(audio.audio_path):\n",
        "            return \"Error: The audio file could not be found. Please try again.\"\n",
        "\n",
        "        try:\n",
        "            # Open the OGG file and send it for transcription\n",
        "            with open(audio.audio_path, \"rb\") as audio_file:\n",
        "                transcription = self.client.audio.transcriptions.create(\n",
        "                    file=audio_file,\n",
        "                    model=\"whisper-large-v3-turbo\",\n",
        "                    language=\"es\",\n",
        "                    temperature=0.0\n",
        "                )\n",
        "                return transcription.text\n",
        "        except Exception:\n",
        "            # Return a generic error message for Streamlit\n",
        "            return \"An error occurred while processing the audio. Please try again.\""
      ],
      "metadata": {
        "id": "4iZe1LFNz-qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stt = STT()\n",
        "\n",
        "# test\n",
        "\n",
        "audio_data = io.BytesIO()\n",
        "with open(\"temp.wav\", \"rb\") as f:\n",
        "    audio_data.write(f.read())\n",
        "audio_data.seek(0)\n",
        "\n",
        "audio1 = Audio(audio_bytes=audio_data)\n",
        "\n",
        "result = stt.obtener_texto(audio1)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq9vYDDEv1XK",
        "outputId": "e1a8de87-de40-4055-ed17-1be2486da1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted to OGG: 7b3d6d91-aee0-458f-a3be-49dfe8f72855.ogg\n",
            " Hola, ¿qué tal? Hola, ¿qué tal?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation Talk"
      ],
      "metadata": {
        "id": "WILmICNwPWog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Talker():\n",
        "  prompt: str = generation_prompt\n",
        "  model: str = \"Meta-Llama-3.1-70B-Instruct\"\n",
        "  client: OpenAI = None\n",
        "\n",
        "  class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "  def __init__(self, **data):\n",
        "        super().__init__(**data)\n",
        "        self.client = OpenAI(\n",
        "            base_url=\"https://api.sambanova.ai/v1/\",\n",
        "            api_key=SAMBANOVA_API_KEY,\n",
        "        )\n",
        "\n",
        "  def response(self, query):\n",
        "\n",
        "    completion = self.client.chat.completions.create(\n",
        "        model=self.model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": self.prompt.format(topic=query),\n",
        "            }\n",
        "        ],\n",
        "        stream=False,\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "\n",
        "    # Procesar el texto\n",
        "    resultado = extraer_contenido(response, \"resultado\")[0].strip()\n",
        "    dialogo = extraer_contenido(response, \"dialogo\")[0].strip()\n",
        "\n",
        "    # Procesar diálogos\n",
        "    orador1_dialogos, orador2_dialogos = procesar_dialogos(dialogo)\n",
        "\n",
        "    return resultado, orador1_dialogos, orador2_dialogos, response"
      ],
      "metadata": {
        "id": "NVMVZwn5iX2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "import os\n",
        "\n",
        "# Configure the LLM to use Cerebras\n",
        "# llm = LLM(\n",
        "#     model=\"groq/llama-3.1-70b-versatile\",  # Replace with your chosen Cerebras model name\n",
        "#     api_key=GROQ_API_KEY,  # Your Cerebras API key\n",
        "#     base_url=\"https://api.groq.com/openai/v1\",\n",
        "#     temperature=0.5,\n",
        "# )\n",
        "llm = LLM(\n",
        "    model=\"sambanova/Meta-Llama-3.1-70B-Instruct\",  # Replace with your chosen Cerebras model name\n",
        "    api_key=SAMBANOVA_API_KEY,  # Your Cerebras API key\n",
        "    base_url=\"https://api.sambanova.ai/v1/\",\n",
        "    temperature=0.5,\n",
        ")\n",
        "\n",
        "# Agent definition\n",
        "orador1 = Agent(\n",
        "    role='Profesora experta y comunicadora científica',\n",
        "    goal='Explicar conceptos complejos de manera accesible, inspirar curiosidad y hacer que el aprendizaje sea entretenido y comprensible',\n",
        "    backstory=\"\"\"Doctora en su campo con más de 15 años de experiencia en investigación y divulgación científica\n",
        "Ha publicado varios libros de divulgación y es conocida por su habilidad para explicar temas complejos de manera sencilla\n",
        "Ha viajado extensamente, recopilando experiencias y ejemplos del mundo real para ilustrar sus explicaciones\n",
        "Tiene un don para convertir información técnica en narrativas fascinantes\n",
        "Apasionada por democratizar el conocimiento y hacerlo accesible para todos\"\"\",\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Agent definition\n",
        "orador2 = Agent(\n",
        "    role='Estudiante periodista científica junior',\n",
        "    goal='Hacer preguntas que ayuden a desentrañar conceptos complejos, representar la perspectiva del oyente común, mantener la conversación dinámica e interesante',\n",
        "    backstory=\"\"\"Periodista científica junior con un máster en comunicación\n",
        "Tiene una habilidad natural para hacer que los temas complejos sean interesantes para el público general\n",
        "Su background incluye entrevistas a científicos de diversas disciplinas\n",
        "Siempre busca historias y ejemplos que hagan que la ciencia sea relatable\n",
        "Entusiasta y enérgica, con un genuino deseo de aprender y comprender el mundo que la rodea\"\"\",\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Agent definition\n",
        "resumidor = Agent(\n",
        "    role='Especialista en Síntesis de Información y Destilación de Contenido Complejo sobre: {topic}',\n",
        "    goal=\"\"\"Extraer la esencia y los puntos fundamentales de contenido extenso\n",
        "Transformar información detallada en resúmenes concisos, claros y estructurados\n",
        "Mantener la integridad y precisión de los conceptos originales durante el proceso de condensación\n",
        "Facilitar la comprensión rápida de temas complejos\"\"\",\n",
        "    backstory=\"\"\"Periodista científica senior con más de 20 años de experiencia en comunicación académica\n",
        "Formación en periodismo científico y comunicación estratégica\n",
        "Maestría en Comunicación Académica con especialización en síntesis de información\n",
        "Experiencia trabajando con investigadores, académicos y equipos editoriales de publicaciones científicas\n",
        "Ha desarrollado una metodología única para condensar información compleja manteniendo su esencia\n",
        "Reconocida por su habilidad para \"destilar océanos de información en gotas de conocimiento\"\n",
        "Ha trabajado en proyectos de síntesis para revistas académicas, plataformas de divulgación científica y editoriales especializadas\n",
        "Domina múltiples herramientas y técnicas de resumen, desde análisis estructural hasta extracción semántica\"\"\",\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Define a research task for the Senior Researcher agent\n",
        "resume_task = Task(\n",
        "    description=\"\"\"Generación de Artículo Estilo Wikipedia del {topic}\n",
        "Crear una entrada enciclopédica detallada y estructurada sobre el tema proporcionado, siguiendo el formato y estilo de Wikipedia.\n",
        "La entrada debe incluir una visión general, contexto histórico, aspectos relevantes, datos precisos y una estructura clara que facilite la comprensión del tema.\n",
        "\"\"\",\n",
        "    expected_output=\"\"\"Un documento con las siguientes secciones:\n",
        "- Introducción\n",
        "- Definición y Conceptos Principales\n",
        "- Historia o Contexto de Origen\n",
        "- Aspectos Clave o Componentes\n",
        "- Impacto o Relevancia\n",
        "- Referencias (si aplica)\n",
        "- Información adicional o secciones específicas según el tema\n",
        "\n",
        "Formato OBLIGATORIO\n",
        "<resumen>\n",
        "[Escriba aquí el resultado del tema de forma estructurada como wikipedia]\n",
        "</resumen>\n",
        "\n",
        "Características:\n",
        "- Lenguaje neutro y objetivo\n",
        "- Información precisa y actualizada\n",
        "- Párrafos concisos y bien estructurados\n",
        "- Uso de subtítulos para facilitar la lectura\n",
        "- Información basada en fuentes confiables\"\"\",\n",
        "    agent=resumidor\n",
        ")\n",
        "\n",
        "# Define a research task for the Senior Researcher agent\n",
        "podcast_task = Task(\n",
        "    description=\"\"\"Generación de Diálogo de Podcast Educativo de: {topic}\n",
        "Producir un diálogo de podcast educativo entre dos oradoras (una experta y una aprendiz curiosa) sobre el tema proporcionado. El diálogo debe ser informativo, entretenido y estructurado, cubriendo 3-5 subtemas principales con un enfoque en hacer el contenido accesible y atractivo para el oyente.\n",
        "\"\"\",\n",
        "    expected_output=\"\"\"Un guion de podcast que incluya:\n",
        "- Saludo y presentación\n",
        "- Introducción\n",
        "- Definición y Conceptos Principales\n",
        "- Historia o Contexto de Origen\n",
        "- Aspectos Clave o Componentes\n",
        "- Impacto o Relevancia\n",
        "- Referencias (si aplica)\n",
        "- Información adicional o secciones específicas según el tema\n",
        "\n",
        "\n",
        "Características del diálogo:\n",
        "- Introducción atractiva del tema\n",
        "- Conversación fluida entre Orador 2 (aprendiz) y Orador 1 (experta)\n",
        "- El Orador 2 comienza el podcast\n",
        "- Cobertura de 3-5 subtemas principales\n",
        "- Uso de \"Orador 1:\" y \"Orador 2:\" para identificar quién habla\n",
        "- Interrupciones y expresiones naturales\n",
        "- Preguntas de seguimiento del Orador 2\n",
        "- Explicaciones detalladas del Orador 1\n",
        "- Anécdotas y analogías para ilustrar conceptos\n",
        "- Tono educativo pero accesible\n",
        "- Mantenimiento del enfoque en el tema principal\n",
        "- Ejemplos del mundo real\n",
        "- Transiciones suaves entre subtemas\n",
        "\n",
        "Formato OBLIGATORIO\n",
        "\n",
        "<dialogo>\n",
        "Orador 1: [Inserte aquí el diálogo del orador 1 en el podcast, comenzando directamente con el Orador 1 dando la bienvenida a los oyentes]\n",
        "Orador 2: [Inserte aquí el diálogo del orador 2 en el podcast]\n",
        "... [Continúe el diálogo completo del podcast con el mismo formato]\n",
        "</dialogo>\n",
        "\n",
        "Características:\n",
        "- Lenguaje neutro y objetivo\n",
        "- Información precisa y actualizada\n",
        "- Párrafos concisos y bien estructurados\n",
        "- Uso de subtítulos para facilitar la lectura\n",
        "- Información basada en fuentes confiables\"\"\",\n",
        "    agent=orador2\n",
        ")\n"
      ],
      "metadata": {
        "id": "JYbkk8iT1aIp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew_podcast = Crew(\n",
        "    agents=[orador1, orador2],\n",
        "    tasks=[podcast_task],\n",
        "    process=Process.sequential,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "crew_resume = Crew(\n",
        "    agents=[resumidor],\n",
        "    tasks=[resume_task],\n",
        "    process=Process.sequential,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT_voEiTBdZd",
        "outputId": "2e47ac6a-848c-44ce-90f0-a5813bdf1796"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result_podcast = crew_podcast.kickoff(inputs={'topic': 'como cuido a mi loro?'})\n",
        "result_resume = crew_resume.kickoff(inputs={'topic': 'como cuido a mi loro?'})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "hTliVbtE4vxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Talker():\n",
        "\n",
        "  class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "  def __init__(self, **data):\n",
        "        super().__init__(**data)\n",
        "\n",
        "  def response(self, query):\n",
        "\n",
        "    result_podcast = crew_podcast.kickoff(inputs={'topic': query})\n",
        "\n",
        "    result_resume = crew_resume.kickoff(inputs={'topic': query})\n",
        "\n",
        "    # Procesar el texto\n",
        "    resultado = extraer_contenido(result_resume.raw, \"resumen\")[0].strip()\n",
        "    dialogo = extraer_contenido(result_podcast.raw, \"dialogo\")[0].strip()\n",
        "\n",
        "    # Procesar diálogos\n",
        "    orador1_dialogos, orador2_dialogos = procesar_dialogos(dialogo)\n",
        "\n",
        "    return resultado, orador1_dialogos, orador2_dialogos"
      ],
      "metadata": {
        "id": "cgd4fccnqdfD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "talker = Talker()\n",
        "\n",
        "resultado, orador1_dialogos, orador2_dialogos = talker.response(\"cancer de mama en perras\")"
      ],
      "metadata": {
        "id": "ICaHMqBEooGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af10828-34b9-40bb-d296-8ae7e04e2d6b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEstudiante periodista científica junior\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mGeneración de Diálogo de Podcast Educativo de: cancer de mama en perras\n",
            "Producir un diálogo de podcast educativo entre dos oradoras (una experta y una aprendiz curiosa) sobre el tema proporcionado. El diálogo debe ser informativo, entretenido y estructurado, cubriendo 3-5 subtemas principales con un enfoque en hacer el contenido accesible y atractivo para el oyente.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEstudiante periodista científica junior\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "<dialogo>\n",
            "Orador 2: ¡Bienvenidos a \"Ciencia para Todos\", el podcast donde exploramos temas científicos de manera accesible y emocionante! Hoy hablaremos sobre un tema que puede afectar a nuestras amigas peludas: el cáncer de mama en perras. Me acompaña la Dra. María Rodríguez, veterinaria especializada en oncología animal. ¡Bienvenida, Dra. Rodríguez!\n",
            "Orador 1: ¡Muchas gracias por invitarme! Estoy emocionada de compartir información sobre este tema tan importante.\n",
            "Orador 2: Comencemos con lo básico. ¿Qué es el cáncer de mama en perras y cuáles son los conceptos principales que debemos entender?\n",
            "Orador 1: El cáncer de mama en perras es un tipo de tumor maligno que se desarrolla en los tejidos mamarios. A diferencia de las mujeres, las perras no tienen un sistema de detección temprana como la mamografía, por lo que es crucial estar atentos a los cambios en la mama de nuestra mascota. Los conceptos clave incluyen la identificación de los síntomas, la importancia de la detección temprana y el tratamiento oportuno.\n",
            "Orador 2: Eso es interesante. ¿Cuál es el contexto de origen del cáncer de mama en perras? ¿Hay algún factor de riesgo específico que debamos conocer?\n",
            "Orador 1: El cáncer de mama en perras puede ser causado por una combinación de factores genéticos, hormonales y ambientales. Las perras que no han sido esterilizadas tienen un mayor riesgo de desarrollar cáncer de mama, ya que los niveles hormonales pueden influir en el crecimiento de los tumores. Además, algunas razas como los Cocker Spaniel y los Poodles tienen una mayor predisposición genética a desarrollar este tipo de cáncer.\n",
            "Orador 2: Entiendo. ¿Cuáles son los aspectos clave o componentes que debemos considerar al evaluar el riesgo de cáncer de mama en nuestras perras?\n",
            "Orador 1: Es importante considerar la edad, la raza, el estado de salud general y la historia médica de nuestra perra. También debemos estar atentos a cualquier cambio en la mama, como bultos, enrojecimiento o secreción. La detección temprana es crucial para un tratamiento efectivo.\n",
            "Orador 2: ¿Cuál es el impacto o relevancia del cáncer de mama en perras en la sociedad actual?\n",
            "Orador 1: El cáncer de mama en perras es un problema de salud animal significativo que puede tener un impacto emocional y financiero en las familias que cuidan de estas mascotas. Es importante que los dueños de mascotas estén informados y tomen medidas preventivas para reducir el riesgo de cáncer de mama en sus perras.\n",
            "Orador 2: ¿Hay algún consejo o recomendación que pueda ofrecer a nuestros oyentes para prevenir o detectar el cáncer de mama en sus perras?\n",
            "Orador 1: Sí, es importante que los dueños de mascotas realicen revisiones regulares de la mama de sus perras, especialmente después de los 5 años de edad. También es crucial esterilizar a las perras antes de los 2 años de edad para reducir el riesgo de cáncer de mama. Además, es importante mantener un peso saludable y proporcionar una dieta equilibrada para reducir el riesgo de enfermedades relacionadas con la obesidad.\n",
            "Orador 2: ¡Excelente consejo, Dra. Rodríguez! ¿Hay alguna referencia o recurso adicional que pueda recomendar a nuestros oyentes para obtener más información sobre el cáncer de mama en perras?\n",
            "Orador 1: Sí, la Asociación Americana de Veterinarios de Animales de Compañía (AAHA) y la Sociedad Americana contra el Cáncer (ACS) ofrecen información y recursos valiosos sobre el cáncer de mama en perras.\n",
            "Orador 2: ¡Muchas gracias, Dra. Rodríguez, por compartir su conocimiento y experiencia con nosotros hoy! Esperamos que esta información sea útil para nuestros oyentes.\n",
            "Orador 1: ¡De nada! Fue un placer compartir información sobre este tema importante.\n",
            "</dialogo>\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEspecialista en Síntesis de Información y Destilación de Contenido Complejo sobre: cancer de mama en perras\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mGeneración de Artículo Estilo Wikipedia del cancer de mama en perras\n",
            "Crear una entrada enciclopédica detallada y estructurada sobre el tema proporcionado, siguiendo el formato y estilo de Wikipedia. \n",
            "La entrada debe incluir una visión general, contexto histórico, aspectos relevantes, datos precisos y una estructura clara que facilite la comprensión del tema.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEspecialista en Síntesis de Información y Destilación de Contenido Complejo sobre: cancer de mama en perras\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "<resumen>\n",
            "\n",
            "**Cáncer de Mama en Perras**\n",
            "\n",
            "El cáncer de mama en perras es un tipo de tumor maligno que afecta a las glándulas mamarias de las hembras caninas. Es uno de los cánceres más comunes en las perras y puede ser letal si no se diagnostica y trata a tiempo.\n",
            "\n",
            "**Definición y Conceptos Principales**\n",
            "\n",
            "El cáncer de mama en perras se define como un tumor maligno que se origina en las células epiteliales de las glándulas mamarias. Los tumores pueden ser benignos o malignos, y los malignos pueden ser carcinomas o sarcomas. Los carcinomas son los más comunes y se originan en las células epiteliales, mientras que los sarcomas se originan en las células del tejido conectivo.\n",
            "\n",
            "**Historia o Contexto de Origen**\n",
            "\n",
            "El cáncer de mama en perras ha sido un problema de salud canina durante siglos. Sin embargo, no fue hasta el siglo XX que se comenzó a estudiar y entender la enfermedad. En la década de 1960, se realizaron los primeros estudios sobre la epidemiología y la patología del cáncer de mama en perras. Desde entonces, se han realizado numerosos estudios para entender la causa y el tratamiento de la enfermedad.\n",
            "\n",
            "**Aspectos Clave o Componentes**\n",
            "\n",
            "* **Factores de riesgo**: La edad, la raza, la obesidad y la falta de esterilización son factores de riesgo para el cáncer de mama en perras.\n",
            "* **Síntomas**: Los síntomas del cáncer de mama en perras pueden incluir la presencia de un bulto o nódulo en la glándula mamaria, dolor, enrojecimiento y secreción.\n",
            "* **Diagnóstico**: El diagnóstico del cáncer de mama en perras se realiza mediante la biopsia de la glándula mamaria afectada.\n",
            "* **Tratamiento**: El tratamiento del cáncer de mama en perras puede incluir la cirugía, la quimioterapia y la radioterapia.\n",
            "\n",
            "**Impacto o Relevancia**\n",
            "\n",
            "El cáncer de mama en perras es un problema de salud canina importante que puede tener un impacto significativo en la calidad de vida de las perras afectadas. La enfermedad puede ser letal si no se diagnostica y trata a tiempo. Sin embargo, con un diagnóstico y tratamiento tempranos, es posible mejorar la supervivencia y la calidad de vida de las perras afectadas.\n",
            "\n",
            "**Referencias**\n",
            "\n",
            "* **American Kennel Club Canine Health Foundation**. (2020). Cáncer de mama en perras.\n",
            "* **World Small Animal Veterinary Association**. (2019). Cáncer de mama en perras.\n",
            "* **Veterinary Cancer Society**. (2018). Cáncer de mama en perras.\n",
            "\n",
            "**Información adicional**\n",
            "\n",
            "* **Prevención**: La esterilización y la alimentación saludable pueden ayudar a prevenir el cáncer de mama en perras.\n",
            "* **Investigación**: La investigación sobre el cáncer de mama en perras sigue en curso para entender mejor la causa y el tratamiento de la enfermedad.\n",
            "\n",
            "</resumen>\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output"
      ],
      "metadata": {
        "id": "xM1SXCI80CYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import IPython"
      ],
      "metadata": {
        "id": "MhQlLEsYWGRJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TTS(BaseModel):\n",
        "  client: gTTS = Field(default=gTTS)\n",
        "\n",
        "  class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "  def generar_audio_text(self, text):\n",
        "        \"\"\"\n",
        "        Reads text\n",
        "        \"\"\"\n",
        "        tts = self.client(text, lang='es', tld='es')\n",
        "\n",
        "        fp = io.BytesIO()\n",
        "        tts.write_to_fp(fp)\n",
        "        # fp.seek(0)\n",
        "\n",
        "        return Audio(audio_bytes=fp, input_format=\"mp3\")\n",
        "\n",
        "  def generar_audio(self, texto, tld='com.mx', velocidad=1.0):\n",
        "\n",
        "        \"\"\"Genera un fragmento de audio a partir de texto.\"\"\"\n",
        "        tts = gTTS(text=texto, lang=\"es\", tld=tld, slow=False)\n",
        "        tts_file = \"temp.mp3\"\n",
        "        tts.save(tts_file)\n",
        "        audio = AudioSegment.from_file(tts_file)\n",
        "        # Ajustar velocidad del audio\n",
        "        return audio.speedup(playback_speed=velocidad)\n",
        "\n",
        "  def generar_conversacion(self, id=str(uuid.uuid4()), orador1_dialogos=[], orador2_dialogos=[], velocidad=1.0, pausa_ms=500, idioma='es'):\n",
        "    \"\"\"\n",
        "    Genera un audio combinado de una conversación entre dos oradores.\n",
        "\n",
        "    Args:\n",
        "        orador1_dialogos (list): Lista de diálogos de Orador 1.\n",
        "        orador2_dialogos (list): Lista de diálogos de Orador 2.\n",
        "        velocidad (float): Velocidad del habla (1.0 es la velocidad normal, >1.0 más rápido, <1.0 más lento).\n",
        "        pausa_ms (int): Tiempo de pausa entre los diálogos en milisegundos.\n",
        "        idioma (str): Idioma para gTTS (por defecto 'es' para español).\n",
        "\n",
        "    Returns:\n",
        "        None: Genera un archivo de audio llamado 'conversacion_completa.mp3'.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(orador1_dialogos)>1 and len(orador2_dialogos)>1:\n",
        "\n",
        "      # Crear audio final fusionado\n",
        "      audio_final = AudioSegment.silent(duration=0)  # Inicializar audio vacío\n",
        "\n",
        "      # Alternar entre los diálogos de ambos oradores\n",
        "      for o1, o2 in zip(orador1_dialogos, orador2_dialogos):\n",
        "          audio_final += self.generar_audio(o2, 'us', velocidad)\n",
        "          audio_final += AudioSegment.silent(duration=pausa_ms)  # Pausa entre oradores\n",
        "          audio_final += self.generar_audio(o1, 'es', velocidad)\n",
        "          audio_final += AudioSegment.silent(duration=pausa_ms)  # Pausa entre oradores\n",
        "\n",
        "      # Si Orador 1 tiene más diálogos, añadir los restantes\n",
        "      for i in range(len(orador2_dialogos), len(orador1_dialogos)):\n",
        "          audio_final += self.generar_audio(orador1_dialogos[i])\n",
        "          audio_final += AudioSegment.silent(duration=pausa_ms)  # Pausa entre oradores\n",
        "\n",
        "      # Guardar el audio combinado\n",
        "      audio_final.export(id+\".mp3\", format=\"mp3\")\n",
        "\n",
        "      return id+\".mp3\"\n"
      ],
      "metadata": {
        "id": "MUQsw503xZQF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "tts = TTS()\n",
        "\n",
        "tts.generar_conversacion(orador1_dialogos=orador1_dialogos, orador2_dialogos=orador2_dialogos, velocidad=1.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ytpwukMNGSxk",
        "outputId": "4ae82b2e-e319-4713-b4be-778cba1f0099"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ebb9a2de-6e30-4a7f-8bd3-4cef86e4bf06.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBcqXh7eG-yK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}